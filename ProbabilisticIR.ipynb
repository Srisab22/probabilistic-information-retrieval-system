{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e4e5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c69d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47c0f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "def load_documents(folder_path):\n",
    "    docs = {}\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
    "                docs[filename] = preprocess(file.read())\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6f1f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load queries\n",
    "def load_queries(query_file_path):\n",
    "    with open(query_file_path, 'r') as file:\n",
    "        return [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eb60444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute term frequencies and document frequencies\n",
    "def compute_statistics(docs):\n",
    "    doc_count = len(docs)\n",
    "    term_doc_freq = defaultdict(int)\n",
    "    term_freq = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for doc_id, words in docs.items():\n",
    "        word_set = set(words)\n",
    "        for word in words:\n",
    "            term_freq[doc_id][word] += 1\n",
    "        for word in word_set:\n",
    "            term_doc_freq[word] += 1\n",
    "\n",
    "    return term_freq, term_doc_freq, doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33c8b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relevance probabilities using BIM\n",
    "def compute_relevance_prob(query, term_freq, term_doc_freq, doc_count):\n",
    "    scores = {}\n",
    "    for doc_id in term_freq:\n",
    "        score = 1.0\n",
    "        for term in query:\n",
    "            tf = term_freq[doc_id].get(term, 0)\n",
    "            df = term_doc_freq.get(term, 0)\n",
    "            p_term_given_relevant = (tf + 1) / (sum(term_freq[doc_id].values()) + len(term_doc_freq))\n",
    "            p_term_given_not_relevant = (df + 1) / (doc_count - df + len(term_doc_freq))\n",
    "            score *= (p_term_given_relevant / p_term_given_not_relevant)\n",
    "        scores[doc_id] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0e7ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main retrieval function\n",
    "def retrieve_documents_and_result(trump_speeches_path, query_file_path, output_file_name):\n",
    "    docs = load_documents(trump_speeches_path)\n",
    "    queries = load_queries(query_file_path)\n",
    "\n",
    "    term_freq, term_doc_freq, doc_count = compute_statistics(docs)\n",
    "\n",
    "    with open(output_file_name, 'w') as results_file:\n",
    "        for query in queries:\n",
    "            query_terms = preprocess(query)\n",
    "            scores = compute_relevance_prob(query_terms, term_freq, term_doc_freq, doc_count)\n",
    "            ranked_docs = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "            results_file.write(f\"Query: {query}\\n\")\n",
    "            for doc_id, score in ranked_docs:\n",
    "                results_file.write(f\"Document: {doc_id}, Score: {score:.4f}\\n\")\n",
    "            results_file.write(\"\\n\")\n",
    "    print(f\"Results written to {output_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "698dab7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to results.txt\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    trump_speeches_path = 'Speechs'\n",
    "    query_file_path =  './query/query1.txt'\n",
    "    output_file_name = 'results.txt'\n",
    "    retrieve_documents_and_result(trump_speeches_path, query_file_path, output_file_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
